{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define environment variables</b>\n",
    "\n",
    "To be used in future training steps.  Note that the BUCKET_NAME defined below must exist in the GCP project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=ross-keras\n",
    "%env LOCAL_JOB_DIR=local-training-output\n",
    "%env JOB_NAME=keras_wnd_job\n",
    "%env REGION=us-central1\n",
    "%env MODEL_NAME=keras_wnd_model\n",
    "%env MODEL_VERSION=v16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training locally</b>\n",
    "\n",
    "Training detail will be written locally to the folder referenced in the job-dir parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train locally\n",
    "!gcloud ai-platform local train \\\n",
    "  --package-path trainer \\\n",
    "  --module-name trainer.task \\\n",
    "  --job-dir $LOCAL_JOB_DIR \n",
    "\n",
    "# parameters can coptionally be explicitly passed into the training module (else defaults will be used)\n",
    "'''\n",
    "  -- \\\n",
    "  --num-deep-layers=1 \\\n",
    "  --first-deep-layer-size=20 \\\n",
    "  --first-wide-layer-size=1168 \\\n",
    "  --learning-rate=0.026203671309666113 \\\n",
    "  --wide-scale-factor=0.37760157070726325 \\\n",
    "  --train-batch-size=27\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform hyperparameter tuning on AI Platform</b>\n",
    "\n",
    "Training detail will be written to Cloud Storage in the folder referenced in the job-dir parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on AI Platform with hyperparameter tuning\n",
    "#  --stream-logs\n",
    "!gcloud ai-platform jobs submit training ${JOB_NAME}_hpt \\\n",
    "  --config hptuning_config.yaml \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region $REGION \\\n",
    "  --python-version 3.5 \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --job-dir gs://${BUCKET_NAME}/keras-job-dir-hpt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training on AI Platform</b>\n",
    "\n",
    "Now that hyperparameters have been tuned, perform deeper training with the optimal hyperparameters in place.  Note that we've increased the training size by explicitly setting the train-steps and train-batch-size parameters in addition to the tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on AI Platform\n",
    "\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region $REGION \\\n",
    "  --python-version 3.5 \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --job-dir gs://${BUCKET_NAME}/keras-job-dir \\\n",
    "  -- \\\n",
    "  --num-deep-layers=1 \\\n",
    "  --first-deep-layer-size=15 \\\n",
    "  --first-wide-layer-size=2085 \\\n",
    "  --learning-rate=0.04 \\\n",
    "  --wide-scale-factor=0.237 \\\n",
    "  --train-batch-size=52 \\\n",
    "  --train-steps=500 \\\n",
    "  --train-batch-size=1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Host the trained model on AI Platform</b>\n",
    "\n",
    "Because we're passing a list of numpy arrays and not a single numpy array as input for inference, we'll need to establish a custom prediction module.  \n",
    "\n",
    "First, execute the setup script to create a distribution tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the tarball over to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp dist/trainer-0.1.tar.gz gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a new model on AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "!gcloud ai-platform models create $MODEL_NAME --regions $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create new version using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a version\n",
    "!gcloud beta ai-platform versions create $MODEL_VERSION \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --python-version 3.5 \\\n",
    "  --origin gs://${BUCKET_NAME}/keras-job-dir \\\n",
    "  --package-uris gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz \\\n",
    "  --prediction-class predictor.MyPredictor\n",
    "        \n",
    "#  --framework tensorflow \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a sample for inference</b>\n",
    "\n",
    "Note that we are using the same preprocessing methods used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for inference\n",
    "!python create_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Make an inference on a new sample.</b>\n",
    "\n",
    "Pass the sample object to the model hosted in AI Platform to return a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the prediction request\n",
    "!gcloud ai-platform predict \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --version $MODEL_VERSION \\\n",
    "  --json-instances input_sample.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
